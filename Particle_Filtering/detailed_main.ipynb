{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "AI Practical Homework5 - Q1\n",
    "</h1>\n",
    "<h2>\n",
    "Particle Filtering Problem\n",
    "</h2>\n",
    "<b>\n",
    "Benyamin Maleki \n",
    "</b> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of radiostations from radio_stations.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_radio_stations():\n",
    "    with open(\"radio_stations.json\", \"r\") as f:\n",
    "        radio_stations = json.load(f)\n",
    "    \n",
    "    radio_station_keys = set()\n",
    "    for name in radio_stations:\n",
    "        radio_station_keys.add(name)\n",
    "\n",
    "    return radio_stations, radio_station_keys\n",
    "\n",
    "radio_stations, radio_station_keys = read_radio_stations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the input file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"input_sample.txt\", \"r\") as f:\n",
    "    initial_coord = np.array([float(x) for x in f.readline().strip().split(\", \")])\n",
    "\n",
    "    step_magnitude_distrib_param = float(f.readline().strip())\n",
    "    cov_matrix_param = float(f.readline().strip())\n",
    "    count_steps_agent = int(f.readline().strip())\n",
    "\n",
    "    estimated_distance = {}\n",
    "    for _ in range(len(radio_stations)):\n",
    "        station_name = f.readline().strip()\n",
    "        for __ in range(count_steps_agent):\n",
    "            dist = float(f.readline().strip())\n",
    "            if station_name not in estimated_distance:\n",
    "                estimated_distance[station_name] = []\n",
    "            estimated_distance[station_name].append(dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling movement of the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movement_vector():\n",
    "    magnitude = np.random.exponential(step_magnitude_distrib_param)\n",
    "    angle_vertical = np.random.uniform(-np.pi/8, 0)\n",
    "    angle_from_x_ax = np.random.uniform(-np.pi/8, np.pi/4)\n",
    "\n",
    "    delta_x = magnitude * np.cos(angle_vertical) * np.cos(angle_from_x_ax)\n",
    "    delta_y = magnitude * np.cos(angle_vertical) * np.sin(angle_from_x_ax)\n",
    "    delta_z = magnitude * np.sin(angle_vertical)\n",
    "    return np.array([delta_x, delta_y, delta_z])\n",
    "\n",
    "def get_cov_matrix():\n",
    "    return np.identity(3) * cov_matrix_param\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform particle filtering on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [1400  300  200]\n"
     ]
    }
   ],
   "source": [
    "def assign_weight_to_particles(particles, step, estimated_distances):\n",
    "    weights = np.zeros(particles.shape[0])\n",
    "    for station_name in radio_station_keys:\n",
    "        # No data of current step movement!\n",
    "        if estimated_distances[station_name][step] == \"None\":\n",
    "            continue\n",
    "        # Assign weight (probability) to each particle\n",
    "        for i in range(particles.shape[0]):\n",
    "            estimated_distance = estimated_distances[station_name][step]\n",
    "            particle_distance = np.linalg.norm(particles[i] - radio_stations[station_name]['coordinates'])\n",
    "            weights[i] += np.exp(-particle_distance / estimated_distance)\n",
    "    return weights\n",
    "\n",
    "def particle_filtering():\n",
    "    particle_count = 100\n",
    "    particles = np.random.multivariate_normal(initial_coord, get_cov_matrix(), particle_count)\n",
    "    for i in range(count_steps_agent):\n",
    "        particles += get_movement_vector()\n",
    "        # resample based on evidence\n",
    "        weights = assign_weight_to_particles(particles, i, estimated_distance)\n",
    "        weights /= weights.sum()\n",
    "        chosen_particle_indices = np.random.choice(np.arange(particle_count), size=particle_count, p=weights)\n",
    "        particles = particles[chosen_particle_indices]\n",
    "    return particles\n",
    "\n",
    "particles = particle_filtering()\n",
    "mean = particles.mean(axis=0)\n",
    "x = int(np.ceil(mean[0]/100)*100)\n",
    "y = int(np.ceil(mean[1]/100)*100)\n",
    "z = int(np.ceil(mean[2]/100)*100)\n",
    "estimated_final_coord = np.array([x, y, z])\n",
    "print(\"Mean: {}\".format(estimated_final_coord))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
